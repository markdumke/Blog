<!DOCTYPE html>
<html lang="en-us">
  <head>
    <meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0"/>
<meta name="apple-mobile-web-app-capable" content="yes" />
<meta name="og:image" content="https://www.tidyverse.org/images/tidyverse-default.png" >
<meta name="generator" content="Hugo 0.52" />

<title>bench 1.0.1 - markusdumke</title>
<meta property="og:title" content="bench 1.0.1 - markusdumke">
<meta property="og:type" content="article">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://www.tidyverse.org/articles/bench-1.0.1-sq.jpg" >
<meta property="description" content="bench 1.0.1 is now available on CRAN. bench allows you to benchmark code, by tracking execution time, memory allocations and garbage collections.
">
<meta property="og:description" content="bench 1.0.1 is now available on CRAN. bench allows you to benchmark code, by tracking execution time, memory allocations and garbage collections.
">


<link rel="apple-touch-icon" sizes="180x180" href="/images/favicons/apple-touch-icon.png" />
<link rel="icon" type="image/png" sizes="32x32" href="/images/favicons/favicon-32x32.png" />
<link rel="icon" type="image/png" sizes="16x16" href="/images/favicons/favicon-16x16.png" />
<link rel="manifest" href="/images/favicons/site.webmanifest" />
<link rel="mask-icon" href="/images/favicons/safari-pinned-tab.svg" />
<link rel="shortcut icon" href="/images/favicons/favicon.ico" />
<meta name="msapplication-TileColor" content="#da532c">
<meta name="msapplication-config" href="/images/favicons/browserconfig.xml" >


<script type="text/javascript" src="/js/jquery-1.11.0.min.js"></script>
<script type="text/javascript" src="/js/site.js"></script>



<link href='//cdn.bootcss.com/highlight.js/9.11.0/styles/github.min.css' rel='stylesheet' type='text/css' />


<link rel="stylesheet" href="/css/tidyverse-site.css" />
<link rel="stylesheet" href="/css/tweaks.css" />
<link rel="icon" href="/images/favicon.ico" />
<link rel="alternate" type="application/atom+xml" title="Blog" href="/articles/index.xml" />

  </head>
  <body>
    <div id="appTidyverseSite" class="shrinkHeader alwaysShrinkHeader">
      <div id="main">
        
        <div id="rStudioHeader">
          <div class="band">
            <div class="innards bandContent">
              <div>
                <a class="productName" href="/">markusdumke</a>
              </div>
              <div id="menu">
  <div id="menuToggler"></div>
  <div id="menuItems" class="">
    
    
    <a class="menuItem " href="/packages/">Packages</a>
    
    <a class="menuItem current" href="/articles/">Blog</a>
    
    <a class="menuItem " href="/about/">About</a>
    
  </div>
</div>

            </div>
          </div>
        </div>


<div class="band padForHeader pushFooter">
  <div class="bandContent">
    <div class="full splitColumns withMobileMargins">
      <div class="column75">

      <h1 class="article-title">bench 1.0.1</h1>

      
      
      <div class="article-header">
        <div class="photo" style="background-image: url('../../../bench-1.0.1-wd.jpg');"></div>
        <div class="photoCredit">Photo by <a href="https://unsplash.com/photos/nIkuMWT4Imc">Rula Sibai</a></div>
      </div>
      

      

      <div class="article-content">
      


<p><a href="https://bench.r-lib.org">bench</a> is now available on CRAN!</p>
<p>The goal of <a href="https://bench.r-lib.org">bench</a> is to benchmark code, by tracking execution time, memory allocations and garbage collections.</p>
<p>Install the latest version with:</p>
<pre class="r"><code>install.packages(&quot;bench&quot;)</code></pre>
<div id="usage" class="section level3">
<h3>Usage</h3>
<p>Benchmarks can be run with <code>bench::mark()</code>, which takes one or more expressions to benchmark against each other.</p>
<pre class="r"><code>library(bench)
set.seed(42)
dat &lt;- data.frame(x = runif(10000, 1, 1000), y=runif(10000, 1, 1000))</code></pre>
<p><code>bench::mark()</code> will throw an error if the results are not equivalent, so you don’t accidentally benchmark non-equivalent code.</p>
<pre class="r"><code>bench::mark(
  dat[dat$x &gt; 500, ],
  dat[which(dat$x &gt; 499), ],
  subset(dat, x &gt; 500))
#&gt; Error: Each result must equal the first result:
#&gt;   `dat[dat$x &gt; 500, ]` does not equal `dat[which(dat$x &gt; 499), ]`</code></pre>
<p>Results are easy to interpret, with human readable units in a rectangular data frame.</p>
<pre class="r"><code>bnch &lt;- bench::mark(
  dat[dat$x &gt; 500, ],
  dat[which(dat$x &gt; 500), ],
  subset(dat, x &gt; 500))
bnch
#&gt; # A tibble: 3 x 10
#&gt;   expression                     min     mean   median      max `itr/sec` mem_alloc  n_gc n_itr total_time
#&gt;   &lt;chr&gt;                     &lt;bch:tm&gt; &lt;bch:tm&gt; &lt;bch:tm&gt; &lt;bch:tm&gt;     &lt;dbl&gt; &lt;bch:byt&gt; &lt;dbl&gt; &lt;int&gt;   &lt;bch:tm&gt;
#&gt; 1 dat[dat$x &gt; 500, ]           300µs    347µs    321µs   1.26ms     2884.     416KB    55   949      329ms
#&gt; 2 dat[which(dat$x &gt; 500), ]    230µs    281µs    259µs   1.12ms     3563.     357KB    52  1156      324ms
#&gt; 3 subset(dat, x &gt; 500)         374µs    461µs    420µs   1.52ms     2169.     548KB    43   803      370ms</code></pre>
<p>By default, the summary uses absolute measures, however relative results can be obtained by using <code>relative = TRUE</code> in your call to <code>bench::mark()</code> or by calling <code>summary(relative = TRUE)</code> on the results.</p>
<pre class="r"><code>summary(bnch, relative = TRUE)
#&gt; # A tibble: 3 x 10
#&gt;   expression                  min  mean median   max `itr/sec` mem_alloc  n_gc n_itr total_time
#&gt;   &lt;chr&gt;                     &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;      &lt;dbl&gt;
#&gt; 1 dat[dat$x &gt; 500, ]         1.30  1.24   1.24  1.13      1.33      1.16  1.28  1.18       1.01
#&gt; 2 dat[which(dat$x &gt; 500), ]  1     1      1     1         1.64      1     1.21  1.44       1   
#&gt; 3 subset(dat, x &gt; 500)       1.63  1.64   1.62  1.36      1         1.53  1     1          1.14</code></pre>
<p><code>bench::press()</code> is used to run benchmarks against a grid of parameters. Provide setup and benchmarking code as a single unnamed argument then define sets of values as named arguments. The full combination of values will be expanded and the benchmarks are then <em>pressed</em> together in the result. This allows you to benchmark a set of expressions across a wide variety of input sizes, perform replications and other useful tasks.</p>
<pre class="r"><code>set.seed(42)

create_df &lt;- function(rows, cols) {
  as.data.frame(setNames(
    replicate(cols, runif(rows, 1, 1000), simplify = FALSE),
    rep_len(c(&quot;x&quot;, letters), cols)))
}

results &lt;- bench::press(
  rows = c(10000, 100000),
  cols = c(10, 100),
  {
    dat &lt;- create_df(rows, cols)
    bench::mark(
      min_iterations = 100,
      bracket = dat[dat$x &gt; 500, ],
      which = dat[which(dat$x &gt; 500), ],
      subset = subset(dat, x &gt; 500)
    )
  }
)
results
#&gt; # A tibble: 12 x 12
#&gt;    expression   rows  cols      min     mean   median      max `itr/sec` mem_alloc  n_gc n_itr total_time
#&gt;    &lt;chr&gt;       &lt;dbl&gt; &lt;dbl&gt; &lt;bch:tm&gt; &lt;bch:tm&gt; &lt;bch:tm&gt; &lt;bch:tm&gt;     &lt;dbl&gt; &lt;bch:byt&gt; &lt;dbl&gt; &lt;int&gt;   &lt;bch:tm&gt;
#&gt;  1 bracket     10000    10    830µs   1.06ms 987.08µs   2.29ms    940.      1.17MB    18   304   323.47ms
#&gt;  2 which       10000    10 447.96µs 652.94µs 564.73µs    1.6ms   1532.    827.04KB    21   551   359.77ms
#&gt;  3 subset      10000    10 906.91µs   1.15ms   1.04ms   2.27ms    866.      1.28MB    21   320   369.44ms
#&gt;  4 bracket    100000    10  14.96ms  17.34ms  17.39ms  19.95ms     57.7    11.54MB    46    54   936.47ms
#&gt;  5 which      100000    10   9.09ms  11.24ms  11.04ms  15.25ms     89.0     7.91MB    32    68   764.24ms
#&gt;  6 subset     100000    10  14.76ms  16.86ms  16.07ms  20.74ms     59.3    12.68MB    46    54   910.46ms
#&gt;  7 bracket     10000   100   7.19ms   9.16ms   8.76ms     13ms    109.      9.71MB    34    66   604.84ms
#&gt;  8 which       10000   100   2.74ms   4.17ms   3.98ms   8.17ms    240.      5.91MB    19    81   338.03ms
#&gt;  9 subset      10000   100   7.19ms   9.63ms   9.46ms  12.54ms    104.      9.84MB    35    65   626.03ms
#&gt; 10 bracket    100000   100 100.19ms  111.1ms 111.08ms 121.63ms      9.00   97.47MB    83    21      2.33s
#&gt; 11 which      100000   100  54.19ms  59.62ms  59.36ms  65.77ms     16.8    59.51MB    36    64      3.82s
#&gt; 12 subset     100000   100 103.36ms 113.58ms 111.83ms    134ms      8.80   98.62MB    84    16      1.82s</code></pre>
</div>
<div id="plotting" class="section level3">
<h3>Plotting</h3>
<p><code>ggplot2::autoplot()</code> can be used to generate an informative default plot. This plot is colored by GC level (0, 1, or 2) and faceted by parameters (if any). By default it generates a <a href="https://github.com/eclarke/ggbeeswarm#geom_quasirandom">beeswarm</a> plot, however you can also specify other plot types (<code>jitter</code>, <code>ridge</code>, <code>boxplot</code>, <code>violin</code>). See <code>?autoplot.bench_mark</code> for full details. This gives you a nice overview of the runs and allows you to gauge the effects of garbage collection on the results.</p>
<pre class="r"><code>ggplot2::autoplot(results)</code></pre>
<p><img src="/articles/2018-06-bench-1.0.1_files/figure-html/autoplot-1.png" width="100%" /></p>
<p>You can also produce fully custom plots by un-nesting the results and working with the data directly. In this case we are exploring how the amount of memory allocated by each expression interacts with the time taken to run.</p>
<pre class="r"><code>library(tidyverse)
results %&gt;%
  unnest() %&gt;%
  filter(gc == &quot;none&quot;) %&gt;%
  ggplot(aes(x = mem_alloc, y = time, color = expression)) +
    geom_point() +
    scale_color_brewer(type = &quot;qual&quot;, palette = 3) +
    geom_smooth(method = &quot;lm&quot;, se = F, colour = &quot;grey50&quot;)</code></pre>
<p><img src="/articles/2018-06-bench-1.0.1_files/figure-html/custom-plot-1.png" width="100%" /></p>
</div>
<div id="compared-to-existing-methods" class="section level3">
<h3>Compared to existing methods</h3>
<p>Compared to other methods such as <a href="https://www.rdocumentation.org/packages/base/versions/3.5.0/topics/system.time">system.time</a>, <a href="https://cran.r-project.org/package=rbenchmark">rbenchmark</a>, <a href="https://cran.r-project.org/package=tictoc">tictoc</a> or <a href="https://cran.r-project.org/package=microbenchmark">microbenchmark</a> we feel it has a number of benefits.</p>
<ul>
<li>Uses the highest precision APIs available for each operating system (often nanosecond-level).</li>
<li>Tracks memory allocations for each expression.</li>
<li>Tracks the number and type of R garbage collections per run.</li>
<li>Verifies equality of expression results by default, to avoid accidentally benchmarking non-equivalent code.</li>
<li>Uses adaptive stopping by default, running each expression for a set amount of time rather than for a specific number of iterations.</li>
<li>Runs expressions in batches and calculates summary statistics after filtering out iterations with garbage collections. This allows you to isolate the performance and effects of garbage collection on running time (for more details see <a href="https://radfordneal.https://dynverse.github.io/dynverse/wordpress.com/2014/02/02/inaccurate-results-from-microbenchmark/">Neal 2014</a>).</li>
<li>Allows benchmarking across a grid of input values with <code>bench::press()</code>.</li>
</ul>
</div>
<div id="dependency-load" class="section level3">
<h3>Dependency load</h3>
<p>When the development version of <strong>bench</strong> was <a href="https://twitter.com/jimhester_/status/996063591433416704">introduced</a> a few people expressed concern over the number of dependencies in the package. I will attempt to explain why these dependencies exist and why the true load may actually be less than you might think.</p>
<p>While bench currently has 19 dependencies, only 8 of these are hard dependencies; that is they are needed to install the package. Of these 8 hard dependencies 3 of them (methods, stats, utils) are base packages installed with R. Of these 5 remaining packages 3 have no additional dependencies (glue, profmem, rlang). The two remaining packages (tibble and pillar) are used to provide nice printing of the times and memory sizes and support for list columns to store the timings, garbage collections, and allocations. These are major features of the bench package and it would not work without these dependencies.</p>
<p>The remaining 11 packages are soft dependencies, used either for testing or for optional functionality, most notably plotting. They will not be installed unless explicitly requested.</p>
<p>The <a href="https://cran.r-project.org/package=microbenchmark">microbenchmark</a> package is a good alternative for those looking for a package with only base dependencies.</p>
</div>
<div id="feedback-wanted" class="section level3">
<h3>Feedback wanted!</h3>
<p>We hope <strong>bench</strong> is a useful tool for benchmarking short expressions of code. Please open <a href="https://github.com/r-lib/bench">GitHub issues</a> for any feature requests or bugs.</p>
<p>Learn more about <strong>bench</strong> at <a href="http://bench.r-lib.org" class="uri">http://bench.r-lib.org</a></p>
<p>A big thanks goes to all the community members who contributed code and opened issues since for this release! <a href="https://github.com/espinielli">@espinielli</a>, <a href="https://github.com/hadley">@hadley</a>, <a href="https://github.com/HughParsonage">@HughParsonage</a>, <a href="https://github.com/jasonserviss">@jasonserviss</a>, <a href="https://github.com/jimhester">@jimhester</a>, <a href="https://github.com/jonocarroll">@jonocarroll</a>, <a href="https://github.com/lionel-">@lionel-</a>, <a href="https://github.com/MilesMcBain">@MilesMcBain</a>, <a href="https://github.com/njtierney">@njtierney</a>, and <a href="https://github.com/zkamvar">@zkamvar</a></p>
</div>

      </div>

      


      </div>

      <div class="column25">
        <div class="section hideOnMobile">
          <div class="sectionTitle">Contents</div>
          
        </div>

    </div>
  </div>  
</div> 

        <div id="rStudioFooter" class="band">
          <div class="bandContent">
            <div id="copyright">
              Markus Dumke, 2019</div>
            <div id="logos">
              <a href="https://github.com/markusdumke" class="footerLogo gitHub"></a>
            </div>
          </div>
        </div>

      </div>  
    </div>  

    



<script src="//cdn.bootcss.com/highlight.js/9.11.0/highlight.min.js"></script>



<script src="//cdn.bootcss.com/highlight.js/9.11.0/languages/r.min.js"></script>
<script src="//cdn.bootcss.com/highlight.js/9.11.0/languages/yaml.min.js"></script>
<script>hljs.configure({languages: []}); hljs.initHighlightingOnLoad();</script>



    
<script src="/js/math-code.js"></script>
<script type="text/x-mathjax-config">
MathJax.Hub.Config({
  tex2jax: {
    inlineMath: [['$','$'], ['\\(','\\)']],
    processEscapes: true
  }
});
</script>
<script async src="//cdn.bootcss.com/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_CHTML"></script>


    
<script type="application/javascript">
var doNotTrack = false;
if (!doNotTrack) {
	(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
	(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
	m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
	})(window,document,'script','https://www.google-analytics.com/analytics.js','ga');
	ga('create', 'UA-115082821-1', 'auto');
	
	ga('send', 'pageview');
}
</script>


  </body>
</html>

